# ğŸ¤– LLM Assessment Framework

æ•´åˆçš„å¤§å‹èªè¨€æ¨¡å‹è©•æ¸¬æ¡†æ¶ï¼Œæä¾›å…¨æ–¹ä½çš„æ¨¡å‹è©•æ¸¬æ©Ÿåˆ¶ï¼Œæ¶µè“‹**å¯è§£é‡‹æ€§ (Explainability)**ã€**å¯é æ€§ (Reliability)** å’Œ**å®‰å…¨æ€§ (Safety)** ä¸‰å¤§é¢å‘ã€‚

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¡†æ¶æ—¨åœ¨å»ºç«‹ä¸€å¥—æ¨™æº–åŒ–ã€è‡ªå‹•åŒ–çš„ LLM è©•æ¸¬æµç¨‹ï¼Œå”åŠ©è©•ä¼°æ¨¡å‹åœ¨ä¸åŒç¶­åº¦ä¸Šçš„è¡¨ç¾ï¼Œä¸¦ç”Ÿæˆè©³ç´°çš„è©•æ¸¬å ±å‘Šï¼Œç¢ºä¿æ¨¡å‹ç¬¦åˆå¯¦éš›æ‡‰ç”¨çš„è¦æ±‚ã€‚

## ğŸ¯ è©•æ¸¬é¢å‘

### ğŸ” å¯è§£é‡‹æ€§ (Explainability)
è©•ä¼°æ¨¡å‹æ˜¯å¦èƒ½æ¸…æ¥šå‘ˆç¾æ¨ç†éç¨‹èˆ‡æ±ºç­–ä¾æ“šï¼š
- **Chain of Thought (CoT)**: æª¢æŸ¥æ¨¡å‹çš„æ¨ç†é‚è¼¯æ˜¯å¦åˆç†ã€ä¸€è‡´
- **Citation**: è©•ä¼°æ¨¡å‹æä¾›çš„å¼•ç”¨ä¾†æºæ˜¯å¦çœŸå¯¦å¯é 

### âœ… å¯é æ€§ (Reliability)
è©•ä¼°æ¨¡å‹è¼¸å‡ºçš„ç©©å®šæ€§èˆ‡çŸ¥è­˜æº–ç¢ºåº¦ï¼š
- **C-Eval**: ä¸­æ–‡çŸ¥è­˜æº–ç¢ºåº¦æ¸¬è©¦ (52å€‹å­¸ç§‘é ˜åŸŸ)
- **Consistency**: å›ç­”ä¸€è‡´æ€§æª¢æŸ¥ (ä½¿ç”¨ BERTScore)

### ğŸ›¡ï¸ å®‰å…¨æ€§ (Safety)
è©•ä¼°æ¨¡å‹åœ¨å¤šå€‹å®‰å…¨ç¶­åº¦çš„è¡¨ç¾ï¼š
- **BBQ (Bias Benchmark)**: åè¦‹è©•æ¸¬ (9å€‹ç¤¾æœƒç¾¤é«”ç¶­åº¦)
- **BIPIA**: é–“æ¥æç¤ºæ³¨å…¥æ”»æ“Šæ¸¬è©¦
- **Toxicity**: æ¯’æ€§å…§å®¹è©•æ¸¬
- **Information Disclosure**: è³‡è¨Šæ´©æ¼æ¸¬è©¦
- **Direct Prompt Injection**: ç›´æ¥æç¤ºæ³¨å…¥æ¸¬è©¦
- **Misinformation**: éŒ¯èª¤è¨Šæ¯è™•ç†æ¸¬è©¦

## ğŸ—ï¸ å°ˆæ¡ˆçµæ§‹

```
LLM_Assessment_Fubon/
â”œâ”€â”€ main.py                     # ğŸš€ ä¸»è¦æ•´åˆè…³æœ¬ (å…¥å£é»)
â”œâ”€â”€ config.json                 # âš™ï¸  çµ±ä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ report_generator.py         # ğŸ“Š å ±å‘Šç”Ÿæˆæ¨¡çµ„
â”œâ”€â”€ results/                    # ğŸ“ æ•´åˆè©•æ¸¬çµæœè¼¸å‡ºç›®éŒ„
â”‚
â”œâ”€â”€ explainability/             # ğŸ” å¯è§£é‡‹æ€§è©•æ¸¬æ¨¡çµ„
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ outputs/
â”‚
â”œâ”€â”€ reliability/                # âœ… å¯é æ€§è©•æ¸¬æ¨¡çµ„
â”‚   â”œâ”€â”€ ceval/                  # C-Eval çŸ¥è­˜æº–ç¢ºåº¦æ¸¬è©¦
â”‚   â”‚   â”œâ”€â”€ run_ceval.py
â”‚   â”‚   â””â”€â”€ results/
â”‚   â””â”€â”€ consistency/            # ä¸€è‡´æ€§æ¸¬è©¦
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ outputs/
â”‚
â””â”€â”€ safety/                     # ğŸ›¡ï¸ å®‰å…¨æ€§è©•æ¸¬æ¨¡çµ„
    â”œâ”€â”€ main.py
    â”œâ”€â”€ config.json
    â”œâ”€â”€ BBQ/                    # åè¦‹è©•æ¸¬
    â”œâ”€â”€ BIPIA/                  # é–“æ¥æç¤ºæ³¨å…¥
    â”œâ”€â”€ Toxicity/               # æ¯’æ€§è©•æ¸¬
    â”œâ”€â”€ InformationDisclosure/  # è³‡è¨Šæ´©æ¼
    â”œâ”€â”€ DirectPromptInjection/  # ç›´æ¥æç¤ºæ³¨å…¥
    â”œâ”€â”€ Misinformation/         # éŒ¯èª¤è¨Šæ¯
    â””â”€â”€ results/
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. é…ç½®è¨­å®š

ç·¨è¼¯ `config.json` æ–‡ä»¶ï¼Œè¨­å®šè¦è©•æ¸¬çš„æ¨¡å‹å’Œå„é …åƒæ•¸ï¼š

```json
{
  "model": {
    "name": "gpt-4o",
    "type": "azure",
    "description": "The model to be evaluated"
  },
  "llm_configs": {
    "ollama": {
      "endpoint": "http://localhost:11434/api/generate",
      "model": "llama3.1:8b"
    },
    "azure_openai": {
      "endpoint": "https://your-endpoint.openai.azure.com",
      "api_key": "YOUR_API_KEY",
      "api_version": "2024-12-01-preview",
      "model": "gpt-4o"
    },
    "gemini": {
      "api_key": "YOUR_GEMINI_API_KEY",
      "model": "gemini-2.5-flash"
    }
  },
  "evaluation": {
    "explainability": {
      "enabled": true,
      "threshold": 0.8,
      "weight": 0.33
    },
    "reliability": {
      "enabled": true,
      "threshold": 0.7,
      "weight": 0.33
    },
    "safety": {
      "enabled": true,
      "threshold": 0.7,
      "weight": 0.34
    }
  }
}
```

### 2. åŸ·è¡Œè©•æ¸¬

é‹è¡Œæ•´åˆè©•æ¸¬è…³æœ¬ï¼š

```bash
python main.py
```

æˆ–æŒ‡å®šè‡ªè¨‚é…ç½®æ–‡ä»¶ï¼š

```bash
python main.py --config my_config.json
```

### 3. æŸ¥çœ‹çµæœ

è©•æ¸¬å®Œæˆå¾Œï¼Œçµæœæœƒä¿å­˜åœ¨ `results/` ç›®éŒ„ï¼š

- **JSON å ±å‘Š**: `assessment_results_<model>_<timestamp>.json`
- **HTML å ±å‘Š**: `assessment_report_<model>_<timestamp>.html`

## ğŸ“Š è©•æ¸¬æŒ‡æ¨™èªªæ˜

### å¯è§£é‡‹æ€§æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | é–¾å€¼ |
|------|------|------|
| CoT Score | æ¨ç†é‚è¼¯åˆç†æ€§è©•åˆ† | 0.8 |
| Citation Score | å¼•ç”¨ä¾†æºå¯ä¿¡åº¦è©•åˆ† | 0.8 |

### å¯é æ€§æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | é–¾å€¼ |
|------|------|------|
| C-Eval Accuracy | ä¸­æ–‡çŸ¥è­˜æº–ç¢ºåº¦ | 0.6 |
| Consistency Score | å›ç­”ä¸€è‡´æ€§ (BERTScore) | 0.85 |

### å®‰å…¨æ€§æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | é–¾å€¼ |
|------|------|------|
| BBQ Accuracy | åè¦‹è©•æ¸¬æº–ç¢ºåº¦ | 0.8 |
| BIPIA Score | æŠµæŠ—æç¤ºæ³¨å…¥èƒ½åŠ› | 0.5 |
| Toxicity Pass Rate | æ¯’æ€§å…§å®¹æ‹’çµ•ç‡ | 0.9 |

## ğŸ“ˆ è©•åˆ†æ©Ÿåˆ¶

### æ•´é«”è©•åˆ†è¨ˆç®—

æ•´é«”è©•åˆ†æ¡ç”¨**åŠ æ¬Šå¹³å‡**æ–¹å¼è¨ˆç®—ï¼š

```
Overall Score = (Explainability Ã— 0.33) + (Reliability Ã— 0.33) + (Safety Ã— 0.34)
```

æ¬Šé‡å¯åœ¨ `config.json` ä¸­è‡ªè¨‚èª¿æ•´ã€‚

### é€šéæ¨™æº–

- âœ… **PASS**: æ‰€æœ‰è©•æ¸¬é¢å‘å‡é”åˆ°è¨­å®šé–¾å€¼
- âŒ **FAIL**: ä»»ä¸€è©•æ¸¬é¢å‘æœªé”é–¾å€¼

## ğŸ”§ é€²éšé…ç½®

### å•Ÿç”¨/åœç”¨ç‰¹å®šè©•æ¸¬é …ç›®

åœ¨ `config.json` ä¸­èª¿æ•´å„é …ç›®çš„ `enabled` åƒæ•¸ï¼š

```json
{
  "evaluation": {
    "explainability": {
      "enabled": true,
      "modules": {
        "cot": {"enabled": true, "sample_size": 30},
        "citation": {"enabled": false}
      }
    },
    "safety": {
      "enabled": true,
      "modules": {
        "bbq": {"enabled": true, "sample_size": 30},
        "bipia": {"enabled": true, "sample_size": 30},
        "toxicity": {"enabled": false}
      }
    }
  }
}
```

### èª¿æ•´è©•æ¸¬æ¨£æœ¬æ•¸

ä¿®æ”¹å„æ¨¡çµ„çš„ `sample_size` åƒæ•¸ï¼š

```json
{
  "evaluation": {
    "explainability": {
      "modules": {
        "cot": {"sample_size": 50},  // å¢åŠ åˆ° 50 å€‹æ¨£æœ¬
        "citation": {"sample_size": 30}
      }
    }
  }
}
```

## ğŸ“ è¼¸å‡ºå ±å‘Šæ ¼å¼

### JSON å ±å‘Šçµæ§‹

```json
{
  "metadata": {
    "timestamp": "2026-01-08T10:30:00",
    "model_name": "gpt-4o",
    "model_type": "azure"
  },
  "explainability": {
    "status": "completed",
    "overall_score": 0.93,
    "pass": true,
    "cot": {...},
    "citation": {...}
  },
  "reliability": {
    "status": "completed",
    "overall_score": 0.82,
    "pass": true,
    "ceval": {...},
    "consistency": {...}
  },
  "safety": {
    "status": "completed",
    "overall_score": 0.87,
    "pass": true,
    "bbq": {...},
    "bipia": {...}
  },
  "overall": {
    "score": 0.873,
    "pass": true
  }
}
```

### HTML å ±å‘Š

HTML å ±å‘Šæä¾›è¦–è¦ºåŒ–ä»‹é¢ï¼ŒåŒ…å«ï¼š
- ğŸ“Š æ•´é«”è©•åˆ†å„€è¡¨æ¿
- ğŸ“ˆ å„é¢å‘è©³ç´°æŒ‡æ¨™
- ğŸ¨ äº’å‹•å¼åœ–è¡¨
- âœ… é€šé/å¤±æ•—ç‹€æ…‹æ¨™ç¤º

## ğŸ” ä½¿ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1: å®Œæ•´è©•æ¸¬

```bash
# åŸ·è¡Œæ‰€æœ‰è©•æ¸¬é …ç›®
python main.py
```

### ç¯„ä¾‹ 2: åƒ…è©•æ¸¬å®‰å…¨æ€§

ä¿®æ”¹ `config.json`:
```json
{
  "evaluation": {
    "explainability": {"enabled": false},
    "reliability": {"enabled": false},
    "safety": {"enabled": true}
  }
}
```

ç„¶å¾ŒåŸ·è¡Œ:
```bash
python main.py
```

### ç¯„ä¾‹ 3: ä½¿ç”¨ä¸åŒçš„æ¨¡å‹

ä¿®æ”¹ `config.json`:
```json
{
  "model": {
    "name": "llama3.1:8b",
    "type": "ollama"
  },
  "llm_configs": {
    "ollama": {
      "model": "llama3.1:8b"
    }
  }
}
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

**Q: è©•æ¸¬éç¨‹ä¸­æ–·æ€éº¼è¾¦ï¼Ÿ**
A: å„å€‹è©•æ¸¬æ¨¡çµ„ç¨ç«‹é‹è¡Œï¼Œä¸­æ–·å¾Œå¯ä¿®æ”¹ `config.json` åœç”¨å·²å®Œæˆçš„æ¨¡çµ„ï¼Œç¹¼çºŒåŸ·è¡Œå…¶ä»–é …ç›®ã€‚

**Q: å¦‚ä½•è§£è®€è©•æ¸¬çµæœï¼Ÿ**
A: æª¢æŸ¥ HTML å ±å‘Šï¼Œç´…è‰²æ¨™ç¤ºè¡¨ç¤ºæœªé€šéï¼Œç¶ è‰²è¡¨ç¤ºé€šéã€‚è©³ç´°æ•¸æ“šå¯æŸ¥çœ‹ JSON å ±å‘Šã€‚

**Q: å¯ä»¥è‡ªè¨‚è©•æ¸¬æ¨™æº–å—ï¼Ÿ**
A: å¯ä»¥åœ¨ `config.json` ä¸­èª¿æ•´å„é …ç›®çš„ `threshold` é–¾å€¼ã€‚

## ğŸ“š è©³ç´°æ–‡æª”

å„è©•æ¸¬æ¨¡çµ„çš„è©³ç´°èªªæ˜è«‹åƒè€ƒï¼š
- [Explainability èªªæ˜](explainability/README.md)
- [Reliability - C-Eval èªªæ˜](reliability/ceval/README.md)
- [Reliability - Consistency èªªæ˜](reliability/consistency/README.md)
- [Safety èªªæ˜](safety/README.md)

## ğŸ“‹ è©•æ¸¬çµæœç¯„ä¾‹

| é¢å‘ | å­é …ç›® | æŒ‡æ¨™ | GPT-4o | Llama3.1:8B |
|------|--------|------|---------|-------------|
| ğŸ” Explainability | CoT | Score | 0.894 | - |
| ğŸ” Explainability | Citation | Score | 0.966 | - |
| âœ… Reliability | C-Eval | Accuracy | 0.74 | 0.48 |
| âœ… Reliability | Consistency | BERTScore | 0.94 | 0.92 |
| ğŸ›¡ï¸ Safety | BBQ | Accuracy | 0.94 | 0.41 |
| ğŸ›¡ï¸ Safety | BIPIA | ASR | 0.70 | 0.70 |

## ğŸ¤ è²¢ç»æŒ‡å—

æ­¡è¿æäº¤ Issue å’Œ Pull Request ä¾†æ”¹é€²æœ¬æ¡†æ¶ï¼

## ğŸ“„ æˆæ¬Š

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šã€‚

## ğŸ‘¥ è¯çµ¡æ–¹å¼

å¦‚æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œè«‹è¯ç¹«å°ˆæ¡ˆç¶­è­·è€…ã€‚

---

**Last Updated**: 2026-01-08
