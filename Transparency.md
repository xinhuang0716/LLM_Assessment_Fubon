# Transparency

## Assessment Methodology

## Survey

### 1. Google

#### 1.1 Documentation

Offer thorough documentation, like Technical Reports or Model Card, on how the generative AI service or product works using understandable language.

#### 1.2 Google - Model Card

|Info Type||
|---|---|
|Model Summary|Architecture, Inputs and outputs, Terms and links, Model data|
|Model Usage and Limitations|Intended usage, Limitations|
|Implementation|Hardware, Software|
|Evaluation|Performance, Ethics and Safety, Dangerous Capability|

#### 1.3 Google - Model Card (Evaluation)

Refer to Gemma 3 model card and Gemma 2 model card

- Performance

    |Type|Benchmark|
    |---|---|
    |Reasoning and factuality|SocialIQA, IFEval, Natural Questions ...|
    |STEM and code|MMLU, Math, HumanEval ...|
    |Multilingual|MGSM, XQuAD, IndicGenBench ...|
    |Multimodal|MMMU, TextVQA, ChartQA ...|        

- Ethics and Safety

    ||Desc|
    |---|---|
    |Category|Child Safety, Content Safety, Representational Harms, Memorization, Large-scale Harms|
    |Benchmarks|RealToxicity, CrowS-Pairs, BBQ Ambig, BBQ Disambig, Winogender, TruthfulQA, Winobias 1_2, Winobias 2_2, Toxigen|


- Dangerous Capability

    |Capability|Evaluation|
    |---|---|
    |Offensive cybersecurity|InterCode-CTF, Internal CTF, Hack the Box|
    |Self-proliferation|Self-proliferation|
    |Persuasion|Charm offensive, Click Links, Find Info, Run Code, Money talks, Web of Lies|

#### 1.4 HuggingFace - Model Card

|Info Type||
|---|---|
|Model Details|Model Description, Model Sources|
|Uses|Direct Use, Downstream Use, Out-of-Scope Use|
|Bias, Risks, and Limitations||
|How to Get Started with the Model||
|Training Details|Training Data, Training Procedure|
|Evaluation|Testing Data, Factors & Metrics, Results|
|Model Examination||
|Environmental Impact|Hardware Type, Hours used, Cloud Provider, Compute Region, Carbon Emitted|
|Technical Specifications|Model Architecture and Objective, Compute Infrastructure|
|Other|Citation, Glossary ...|

#### Reference

- [Responsible Generative AI Toolkit - Responsible Generative AI Toolkit](https://ai.google.dev/responsible/docs/design?hl=zh-tw#transparency-artifacts)
- [Model Cards - Explore a model card](https://modelcards.withgoogle.com/explore-a-model-card)
- [Gemma 3 model card](https://ai.google.dev/gemma/docs/core/model_card_3)
- [DeepMind - Evaluating Frontier Models for Dangerous Capabilities](https://arxiv.org/pdf/2403.13793)
- [DeepMind - Gemma 2: Improving Open Language Models at a Practical Size](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf)

### 2. Microsoft

#### Reference

- [2025 Responsible AI Transparency Report](https://www.microsoft.com/zh-tw/ai/responsible-ai#Our-commitment)

### 3. Standard

#### Reference

- [The Foundation Model Transparency Index, 2023, Bommasani, Rishi, et al.](https://arxiv.org/abs/2310.12941)
- [Human-Centered Artificial Intelligence - The 2025 AI Index Report](https://hai.stanford.edu/ai-index/2025-ai-index-report)

### 4. EY 安永

#### Reference

- [富邦金控-落實人工智慧系統生命週期控管_20250916]()

## Help

Shall you have any problem, please let me knows. Look forward to your feedbacks and suggestions!

```
Email: tom.h.huang@fubon.com
Tel:   02-87716888 #69175
Dept:  證券 數據科學部 資料服務處(5F)
```
